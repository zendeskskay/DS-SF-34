{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-34 | 18 | Natural Language Processing | Codelong | Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "# '''\n",
    "\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A | Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, model_selection, metrics, decomposition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', u'wait', u'anoth', u'third']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B | Book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)  We scrapped this dataset during class 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'dataset-18-reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>R3TUANQ2EB3ECB</td>\n",
       "      <td>MichaelMichaels</td>\n",
       "      <td>Skip it. Life is too short.</td>\n",
       "      <td>I've never read any of the Harry Potter books ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>R2DD03ZZ4218VW</td>\n",
       "      <td>Frans van Wyk</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Excellent Read with a lot of real life values ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>R296NVKLH5QS4W</td>\n",
       "      <td>Sabina Duke</td>\n",
       "      <td>Characters</td>\n",
       "      <td>Hard to keep the characters straight</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>R3MP7W8LH6VHU8</td>\n",
       "      <td>Jen Blau</td>\n",
       "      <td>GIVE IT A CHANCE!</td>\n",
       "      <td>I almost put this book down. I'm new to Rowlin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>RZWP48RKJCXT1</td>\n",
       "      <td>Lilith Eleanor</td>\n",
       "      <td>Frighteningly good</td>\n",
       "      <td>Amazing. Rowling combines fantastic writing wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>RT2TE0W92SL67</td>\n",
       "      <td>Tricia K.</td>\n",
       "      <td>Seriously?  $17 bucks for a computer file???  ...</td>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R14ZGYPSP9H0Y7</td>\n",
       "      <td>Pretzel</td>\n",
       "      <td>A must read</td>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R1913ISIDAGQ1A</td>\n",
       "      <td>Prodigy</td>\n",
       "      <td>I love it</td>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R2JY771IW7RI3R</td>\n",
       "      <td>David Katz</td>\n",
       "      <td>Kendle price too expensive</td>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R22B7K1DUJR6ZN</td>\n",
       "      <td>M. A. Barnett</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date              id           author  \\\n",
       "0     2017-04-21  R3TUANQ2EB3ECB  MichaelMichaels   \n",
       "1     2017-04-20  R2DD03ZZ4218VW    Frans van Wyk   \n",
       "2     2017-04-20  R296NVKLH5QS4W      Sabina Duke   \n",
       "3     2017-04-05  R3MP7W8LH6VHU8         Jen Blau   \n",
       "4     2017-04-04   RZWP48RKJCXT1   Lilith Eleanor   \n",
       "...          ...             ...              ...   \n",
       "5856  2012-09-27   RT2TE0W92SL67        Tricia K.   \n",
       "5857  2012-09-27  R14ZGYPSP9H0Y7          Pretzel   \n",
       "5858  2012-09-27  R1913ISIDAGQ1A          Prodigy   \n",
       "5859  2012-09-27  R2JY771IW7RI3R       David Katz   \n",
       "5860  2012-09-27  R22B7K1DUJR6ZN    M. A. Barnett   \n",
       "\n",
       "                                                  title  \\\n",
       "0                           Skip it. Life is too short.   \n",
       "1                                            Four Stars   \n",
       "2                                            Characters   \n",
       "3                                     GIVE IT A CHANCE!   \n",
       "4                                    Frighteningly good   \n",
       "...                                                 ...   \n",
       "5856  Seriously?  $17 bucks for a computer file???  ...   \n",
       "5857                                        A must read   \n",
       "5858                                          I love it   \n",
       "5859                         Kendle price too expensive   \n",
       "5860                                      too expensive   \n",
       "\n",
       "                                                   body  star_rating  \n",
       "0     I've never read any of the Harry Potter books ...            1  \n",
       "1     Excellent Read with a lot of real life values ...            4  \n",
       "2                  Hard to keep the characters straight            4  \n",
       "3     I almost put this book down. I'm new to Rowlin...            5  \n",
       "4     Amazing. Rowling combines fantastic writing wi...            5  \n",
       "...                                                 ...          ...  \n",
       "5856  Premise sounds dull as dirt.  For $17 for a co...            1  \n",
       "5857  The depth of character development and storyli...            5  \n",
       "5858  The book was great and I will love to re-read ...            5  \n",
       "5859  I started to order the kindle edition and than...            5  \n",
       "5860  I would love to buy this book but it is too ex...            1  \n",
       "\n",
       "[5861 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['date', 'id', 'author', 'title'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've never read any of the Harry Potter books ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent Read with a lot of real life values ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard to keep the characters straight</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I almost put this book down. I'm new to Rowlin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing. Rowling combines fantastic writing wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  star_rating\n",
       "0     I've never read any of the Harry Potter books ...            1\n",
       "1     Excellent Read with a lot of real life values ...            4\n",
       "2                  Hard to keep the characters straight            4\n",
       "3     I almost put this book down. I'm new to Rowlin...            5\n",
       "4     Amazing. Rowling combines fantastic writing wi...            5\n",
       "...                                                 ...          ...\n",
       "5856  Premise sounds dull as dirt.  For $17 for a co...            1\n",
       "5857  The depth of character development and storyli...            5\n",
       "5858  The book was great and I will love to re-read ...            5\n",
       "5859  I started to order the kindle edition and than...            5\n",
       "5860  I would love to buy this book but it is too ex...            1\n",
       "\n",
       "[5861 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body           3\n",
       "star_rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive, neutral, and negatives reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2711\n",
       "-1    2177\n",
       " 0     970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df['polarity'] = df.star_rating.map({1: -1, 2: -1, 3: 0, 4: 1, 5: 1})\n",
    "ns = df.polarity.value_counts()\n",
    "ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downsampling**: take the lowest count and make the others match (970 of each category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for polarity in [-1,0,1]:\n",
    "    n = ns[polarity] - ns.min()\n",
    "    index = df[df.polarity == polarity].sample(n = n, random_state = 0).index\n",
    "    df.drop(index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsampling**: similar but with replication of the lower represented classes\n",
    "- if you do upsampling you must split first!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    970\n",
       "-1    970\n",
       " 0    970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df['polarity'] = df.star_rating.map({1: -1, 2: -1, 3: 0, 4: 1, 5: 1})\n",
    "ns = df.polarity.value_counts()\n",
    "ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix and response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "X = df['body']\n",
    "c = df.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_c, test_c = model_selection.train_test_split(X, c, stratify = c, train_size = .6, random_state = 0)\n",
    "#stratify: just in case you have something very imbalanced, this will keep the proportions between train and test \n",
    "#random_state: means that the results will be replicable each time you run it because it will use the same randomization\n",
    "#if you do upsampling you must split first!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF and `TfidfVectorizer`\n",
    "Term Frequency (TF) Inverse Document Frequency (IDF)\n",
    "\n",
    "`tf(t,d) = number of occurences of term t in document d / number of terms in document d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer(object):\n",
    "    def __call__(self, document):\n",
    "        tokens = tokenize_text(document)\n",
    "        tokens = Stemmer.stem_tokens(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer = CustomTokenizer(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'012315',\n",
       " u'08',\n",
       " u'1',\n",
       " u'10',\n",
       " u'100',\n",
       " u'1000',\n",
       " u'1012',\n",
       " u'105',\n",
       " u'11',\n",
       " u'110',\n",
       " u'12',\n",
       " u'120',\n",
       " u'13',\n",
       " u'130',\n",
       " u'132',\n",
       " u'14',\n",
       " u'142',\n",
       " u'143',\n",
       " u'149',\n",
       " u'1495',\n",
       " u'1499',\n",
       " u'15',\n",
       " u'150',\n",
       " u'17',\n",
       " u'170',\n",
       " u'175',\n",
       " u'1799',\n",
       " u'18',\n",
       " u'1860',\n",
       " u'18th',\n",
       " u'1950',\n",
       " u'1960',\n",
       " u'1984',\n",
       " u'19th',\n",
       " u'1star',\n",
       " u'2',\n",
       " u'20',\n",
       " u'200',\n",
       " u'2012',\n",
       " u'2015',\n",
       " u'2016',\n",
       " u'21',\n",
       " u'21st',\n",
       " u'23',\n",
       " u'230am',\n",
       " u'236',\n",
       " u'24',\n",
       " u'25',\n",
       " u'250',\n",
       " u'27',\n",
       " u'28',\n",
       " u'2nd',\n",
       " u'3',\n",
       " u'30',\n",
       " u'300',\n",
       " u'3000',\n",
       " u'31',\n",
       " u'32',\n",
       " u'34',\n",
       " u'35',\n",
       " u'355',\n",
       " u'380',\n",
       " u'3d',\n",
       " u'3rd',\n",
       " u'4',\n",
       " u'40',\n",
       " u'400',\n",
       " u'40ish',\n",
       " u'412star',\n",
       " u'44',\n",
       " u'45',\n",
       " u'450',\n",
       " u'5',\n",
       " u'50',\n",
       " u'500',\n",
       " u'500th',\n",
       " u'503',\n",
       " u'505',\n",
       " u'50th',\n",
       " u'56',\n",
       " u'57',\n",
       " u'6',\n",
       " u'60',\n",
       " u'600',\n",
       " u'6080',\n",
       " u'62',\n",
       " u'6th',\n",
       " u'7',\n",
       " u'70',\n",
       " u'72',\n",
       " u'75',\n",
       " u'77',\n",
       " u'8',\n",
       " u'80',\n",
       " u'800',\n",
       " u'89',\n",
       " u'90',\n",
       " u'92',\n",
       " u'93',\n",
       " u'98',\n",
       " u'9997',\n",
       " u'aand',\n",
       " u'aback',\n",
       " u'abandon',\n",
       " u'abil',\n",
       " u'abject',\n",
       " u'abl',\n",
       " u'abnorm',\n",
       " u'abort',\n",
       " u'abound',\n",
       " u'aboutth',\n",
       " u'abraham',\n",
       " u'abrupt',\n",
       " u'abruptli',\n",
       " u'absenc',\n",
       " u'absentmindedli',\n",
       " u'absolut',\n",
       " u'absorb',\n",
       " u'absurd',\n",
       " u'abund',\n",
       " u'abus',\n",
       " u'abut',\n",
       " u'accent',\n",
       " u'accept',\n",
       " u'access',\n",
       " u'accid',\n",
       " u'accident',\n",
       " u'accomplish',\n",
       " u'accord',\n",
       " u'account',\n",
       " u'accur',\n",
       " u'accuraci',\n",
       " u'accus',\n",
       " u'accustom',\n",
       " u'acerb',\n",
       " u'ach',\n",
       " u'achiev',\n",
       " u'acknowledg',\n",
       " u'acom',\n",
       " u'acorn',\n",
       " u'acquaint',\n",
       " u'across',\n",
       " u'act',\n",
       " u'action',\n",
       " u'actionpack',\n",
       " u'activ',\n",
       " u'activit',\n",
       " u'actor',\n",
       " u'actress',\n",
       " u'actual',\n",
       " u'acumen',\n",
       " u'acut',\n",
       " u'ad',\n",
       " u'adapt',\n",
       " u'add',\n",
       " u'addict',\n",
       " u'addit',\n",
       " u'address',\n",
       " u'adept',\n",
       " u'adeptli',\n",
       " u'adequ',\n",
       " u'adjac',\n",
       " u'adject',\n",
       " u'adjust',\n",
       " u'adloesc',\n",
       " u'administ',\n",
       " u'admir',\n",
       " u'admit',\n",
       " u'admittedli',\n",
       " u'adolesc',\n",
       " u'ador',\n",
       " u'adrian',\n",
       " u'adult',\n",
       " u'adulthood',\n",
       " u'adultthem',\n",
       " u'adut',\n",
       " u'advantag',\n",
       " u'adventur',\n",
       " u'advert',\n",
       " u'advertis',\n",
       " u'advic',\n",
       " u'advis',\n",
       " u'advoc',\n",
       " u'affair',\n",
       " u'affect',\n",
       " u'affluent',\n",
       " u'afraid',\n",
       " u'aftermath',\n",
       " u'afternoon',\n",
       " u'afterward',\n",
       " u'agatha',\n",
       " u'age',\n",
       " u'ageless',\n",
       " u'agenda',\n",
       " u'agent',\n",
       " u'agesa',\n",
       " u'aggress',\n",
       " u'agit',\n",
       " u'ago',\n",
       " u'agre',\n",
       " u'ahead',\n",
       " u'ai',\n",
       " u'aid',\n",
       " u'aim',\n",
       " u'aimless',\n",
       " u'air',\n",
       " u'airport',\n",
       " u'aka',\n",
       " u'akin',\n",
       " u'al',\n",
       " u'ala',\n",
       " u'albeit',\n",
       " u'alcohol',\n",
       " u'alert',\n",
       " u'alexand',\n",
       " u'alik',\n",
       " u'aliv',\n",
       " u'alleg',\n",
       " u'allegi',\n",
       " u'allegor',\n",
       " u'alley',\n",
       " u'alli',\n",
       " u'allnight',\n",
       " u'allot',\n",
       " u'allow',\n",
       " u'allround',\n",
       " u'alltim',\n",
       " u'allus',\n",
       " u'allveri',\n",
       " u'almost',\n",
       " u'alon',\n",
       " u'along',\n",
       " u'alot',\n",
       " u'alreadi',\n",
       " u'alright',\n",
       " u'also',\n",
       " u'altern',\n",
       " u'although',\n",
       " u'altogeth',\n",
       " u'altruism',\n",
       " u'alway',\n",
       " u'amateurish',\n",
       " u'amaz',\n",
       " u'amazingli',\n",
       " u'amazom',\n",
       " u'amazon',\n",
       " u'amazoncom',\n",
       " u'amazonon',\n",
       " u'ambigu',\n",
       " u'ambit',\n",
       " u'ambiti',\n",
       " u'ambival',\n",
       " u'america',\n",
       " u'american',\n",
       " u'ami',\n",
       " u'amidst',\n",
       " u'amiss',\n",
       " u'among',\n",
       " u'amongst',\n",
       " u'amount',\n",
       " u'amus',\n",
       " u'analog',\n",
       " u'andi',\n",
       " u'andor',\n",
       " u'anecdot',\n",
       " u'aneurysm',\n",
       " u'angel',\n",
       " u'anger',\n",
       " u'angl',\n",
       " u'anglophil',\n",
       " u'angri',\n",
       " u'angst',\n",
       " u'ann',\n",
       " u'anniversari',\n",
       " u'announc',\n",
       " u'annoy',\n",
       " u'anoth',\n",
       " u'anotherth',\n",
       " u'answer',\n",
       " u'antagonist',\n",
       " u'anticip',\n",
       " u'anticlimact',\n",
       " u'anticlimat',\n",
       " u'antifield',\n",
       " u'antihero',\n",
       " u'antiheroin',\n",
       " u'antip',\n",
       " u'antithesi',\n",
       " u'anxieti',\n",
       " u'anxiou',\n",
       " u'anybodi',\n",
       " u'anyday',\n",
       " u'anymor',\n",
       " u'anyon',\n",
       " u'anyth',\n",
       " u'anytown',\n",
       " u'anyway',\n",
       " u'anywher',\n",
       " u'apart',\n",
       " u'apathi',\n",
       " u'apologet',\n",
       " u'appal',\n",
       " u'appar',\n",
       " u'appeal',\n",
       " u'appear',\n",
       " u'applaud',\n",
       " u'applaus',\n",
       " u'appli',\n",
       " u'appreci',\n",
       " u'apprehens',\n",
       " u'apprentic',\n",
       " u'approach',\n",
       " u'appropri',\n",
       " u'approv',\n",
       " u'approxim',\n",
       " u'apt',\n",
       " u'arc',\n",
       " u'archetyp',\n",
       " u'archvillain',\n",
       " u'area',\n",
       " u'arena',\n",
       " u'arf',\n",
       " u'arguabl',\n",
       " u'argument',\n",
       " u'aris',\n",
       " u'arm',\n",
       " u'armi',\n",
       " u'aros',\n",
       " u'around',\n",
       " u'arous',\n",
       " u'arrang',\n",
       " u'array',\n",
       " u'arriv',\n",
       " u'arrog',\n",
       " u'art',\n",
       " u'artist',\n",
       " u'artistri',\n",
       " u'asan',\n",
       " u'asap',\n",
       " u'asham',\n",
       " u'asid',\n",
       " u'ask',\n",
       " u'asleep',\n",
       " u'aspect',\n",
       " u'aspir',\n",
       " u'assault',\n",
       " u'assess',\n",
       " u'assid',\n",
       " u'assign',\n",
       " u'associ',\n",
       " u'assuag',\n",
       " u'assum',\n",
       " u'assumpt',\n",
       " u'assur',\n",
       " u'astonish',\n",
       " u'astonishingli',\n",
       " u'astound',\n",
       " u'astoundingli',\n",
       " u'astut',\n",
       " u'ate',\n",
       " u'athlet',\n",
       " u'atmospher',\n",
       " u'atrisk',\n",
       " u'attach',\n",
       " u'attack',\n",
       " u'attempt',\n",
       " u'attend',\n",
       " u'attent',\n",
       " u'attitud',\n",
       " u'attorney',\n",
       " u'attract',\n",
       " u'audibl',\n",
       " u'audienc',\n",
       " u'audio',\n",
       " u'audiobook',\n",
       " u'aunt',\n",
       " u'austen',\n",
       " u'australia',\n",
       " u'authent',\n",
       " u'author',\n",
       " u'authoress',\n",
       " u'authori',\n",
       " u'avail',\n",
       " u'avalanch',\n",
       " u'averag',\n",
       " u'avid',\n",
       " u'avoid',\n",
       " u'aw',\n",
       " u'await',\n",
       " u'awak',\n",
       " u'awar',\n",
       " u'away',\n",
       " u'awe',\n",
       " u'awesom',\n",
       " u'awhil',\n",
       " u'awkward',\n",
       " u'awkwardli',\n",
       " u'babi',\n",
       " u'back',\n",
       " u'backbit',\n",
       " u'backdoor',\n",
       " u'backdrop',\n",
       " u'backfir',\n",
       " u'background',\n",
       " u'backstab',\n",
       " u'backstori',\n",
       " u'backward',\n",
       " u'bad',\n",
       " u'badli',\n",
       " u'bag',\n",
       " u'balanc',\n",
       " u'ball',\n",
       " u'banal',\n",
       " u'band',\n",
       " u'barbara',\n",
       " u'bare',\n",
       " u'barri',\n",
       " u'barrymor',\n",
       " u'base',\n",
       " u'basebal',\n",
       " u'bash',\n",
       " u'basi',\n",
       " u'basic',\n",
       " u'basket',\n",
       " u'basketbal',\n",
       " u'bat',\n",
       " u'bate',\n",
       " u'bath',\n",
       " u'bathroom',\n",
       " u'bbc',\n",
       " u'bc',\n",
       " u'be',\n",
       " u'beach',\n",
       " u'bear',\n",
       " u'beast',\n",
       " u'beat',\n",
       " u'beater',\n",
       " u'beauti',\n",
       " u'becacaus',\n",
       " u'becam',\n",
       " u'becom',\n",
       " u'bed',\n",
       " u'bedroom',\n",
       " u'bedtim',\n",
       " u'began',\n",
       " u'beget',\n",
       " u'begin',\n",
       " u'beguil',\n",
       " u'behav',\n",
       " u'behavior',\n",
       " u'behaviour',\n",
       " u'behind',\n",
       " u'being',\n",
       " u'belief',\n",
       " u'believ',\n",
       " u'bellchapel',\n",
       " u'belli',\n",
       " u'belliger',\n",
       " u'belong',\n",
       " u'belov',\n",
       " u'beneath',\n",
       " u'benefit',\n",
       " u'beset',\n",
       " u'best',\n",
       " u'bestsel',\n",
       " u'besttak',\n",
       " u'betray',\n",
       " u'better',\n",
       " u'bevi',\n",
       " u'beyond',\n",
       " u'beyondthi',\n",
       " u'bias',\n",
       " u'bibl',\n",
       " u'bibliophil',\n",
       " u'bicker',\n",
       " u'big',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigotri',\n",
       " u'billion',\n",
       " u'billionair',\n",
       " u'binchi',\n",
       " u'bind',\n",
       " u'bing',\n",
       " u'bird',\n",
       " u'birthday',\n",
       " u'bit',\n",
       " u'bite',\n",
       " u'bitter',\n",
       " u'bitterlki',\n",
       " u'black',\n",
       " u'blackandwhit',\n",
       " u'blade',\n",
       " u'blame',\n",
       " u'blanch',\n",
       " u'bland',\n",
       " u'blank',\n",
       " u'blatantli',\n",
       " u'bleak',\n",
       " u'bleaker',\n",
       " u'bleed',\n",
       " u'blend',\n",
       " u'bless',\n",
       " u'blind',\n",
       " u'blister',\n",
       " u'bloat',\n",
       " u'blockbust',\n",
       " u'blog',\n",
       " u'bloodbath',\n",
       " u'bloodi',\n",
       " u'bloodthirsti',\n",
       " u'blossom',\n",
       " u'blow',\n",
       " u'blue',\n",
       " u'blunt',\n",
       " u'blur',\n",
       " u'blurb',\n",
       " u'boar',\n",
       " u'board',\n",
       " u'bog',\n",
       " u'bogg',\n",
       " u'bold',\n",
       " u'boldli',\n",
       " u'bomb',\n",
       " u'bone',\n",
       " u'boo',\n",
       " u'book',\n",
       " u'booker',\n",
       " u'booki',\n",
       " u'bookjust',\n",
       " u'bookmark',\n",
       " u'booknot',\n",
       " u'booksbett',\n",
       " u'bookslet',\n",
       " u'bookso',\n",
       " u'bookstor',\n",
       " u'bookth',\n",
       " u'boom',\n",
       " u'boorish',\n",
       " u'border',\n",
       " u'bore',\n",
       " u'boredom',\n",
       " u'boreingfound',\n",
       " u'borrow',\n",
       " u'bother',\n",
       " u'bottom',\n",
       " u'bottomlin',\n",
       " u'bought',\n",
       " u'bounc',\n",
       " u'bow',\n",
       " u'box',\n",
       " u'boy',\n",
       " u'boyfriend',\n",
       " u'brace',\n",
       " u'brain',\n",
       " u'branch',\n",
       " u'brandnew',\n",
       " u'brava',\n",
       " u'bravado',\n",
       " u'brave',\n",
       " u'bravo',\n",
       " u'breadth',\n",
       " u'break',\n",
       " u'breakaway',\n",
       " u'breaker',\n",
       " u'breast',\n",
       " u'breath',\n",
       " u'breathtak',\n",
       " u'breed',\n",
       " u'bridgewat',\n",
       " u'brief',\n",
       " u'briefli',\n",
       " u'brighter',\n",
       " u'brightest',\n",
       " u'brillant',\n",
       " u'brillianc',\n",
       " u'brilliant',\n",
       " u'brillianti',\n",
       " u'brilliantli',\n",
       " u'bring',\n",
       " u'brit',\n",
       " u'britain',\n",
       " u'british',\n",
       " u'britisk',\n",
       " u'britney',\n",
       " u'broad',\n",
       " u'broken',\n",
       " u'brooksid',\n",
       " u'broomstick',\n",
       " u'brought',\n",
       " u'brown',\n",
       " u'brutal',\n",
       " u'bu',\n",
       " u'buck',\n",
       " u'bucket',\n",
       " u'bucol',\n",
       " u'budget',\n",
       " u'buffet',\n",
       " u'buffoon',\n",
       " u'build',\n",
       " u'built',\n",
       " u'builtin',\n",
       " u'bull',\n",
       " u'bulli',\n",
       " u'bum',\n",
       " u'bummer',\n",
       " u'bunch',\n",
       " u'burner',\n",
       " u'burst',\n",
       " u'busi',\n",
       " u'button',\n",
       " u'buy',\n",
       " u'c',\n",
       " u'ca',\n",
       " u'calam',\n",
       " u'calendar',\n",
       " u'calib',\n",
       " u'call',\n",
       " u'came',\n",
       " u'camp',\n",
       " u'campaign',\n",
       " u'canari',\n",
       " u'candid',\n",
       " u'candl',\n",
       " u'canon',\n",
       " u'cant',\n",
       " u'cantwo',\n",
       " u'capabl',\n",
       " u'capac',\n",
       " u'capit',\n",
       " u'capitalist',\n",
       " u'capitil',\n",
       " u'captiv',\n",
       " u'captur',\n",
       " u'car',\n",
       " u'caract',\n",
       " u'cardboard',\n",
       " u'cardboardlik',\n",
       " u'care',\n",
       " u'career',\n",
       " u'caricatur',\n",
       " u'carol',\n",
       " u'carpentri',\n",
       " u'carri',\n",
       " u'cartoonish',\n",
       " u'case',\n",
       " u'cash',\n",
       " u'cast',\n",
       " u'castl',\n",
       " u'casual',\n",
       " u'cat',\n",
       " u'cataclysm',\n",
       " u'catalyst',\n",
       " u'catapult',\n",
       " u'catastroph',\n",
       " u'catch',\n",
       " u'catcher',\n",
       " u'categor',\n",
       " u'categori',\n",
       " u'caught',\n",
       " u'cauldron',\n",
       " u'caus',\n",
       " u'causal',\n",
       " u'caustic',\n",
       " u'cave',\n",
       " u'caveat',\n",
       " u'cd',\n",
       " u'celebr',\n",
       " u'cent',\n",
       " u'center',\n",
       " u'centr',\n",
       " u'central',\n",
       " u'centuri',\n",
       " u'certain',\n",
       " u'certainli',\n",
       " u'cesspool',\n",
       " u'chadha',\n",
       " u'chain',\n",
       " u'chairman',\n",
       " u'chalk',\n",
       " u'challeng',\n",
       " u'challengesstruggl',\n",
       " u'chanc',\n",
       " u'chang',\n",
       " u'chao',\n",
       " u'chapter',\n",
       " u'charact',\n",
       " u'character',\n",
       " u'characterdriven',\n",
       " u'characteris',\n",
       " u'characterist',\n",
       " u'charactersand',\n",
       " u'charactersplot',\n",
       " u'charactor',\n",
       " u'charcat',\n",
       " u'charcter',\n",
       " u'charg',\n",
       " u'charit',\n",
       " u'chariti',\n",
       " u'charli',\n",
       " u'charm',\n",
       " u'chart',\n",
       " u'chase',\n",
       " u'chatter',\n",
       " u'chatti',\n",
       " u'cheap',\n",
       " u'cheat',\n",
       " u'check',\n",
       " u'checklist',\n",
       " u'cheer',\n",
       " u'chew',\n",
       " u'chic',\n",
       " u'chief',\n",
       " u'child',\n",
       " u'childhood',\n",
       " u'children',\n",
       " u'childrensteen',\n",
       " u'childrenyoung',\n",
       " u'chill',\n",
       " u'chimera',\n",
       " u'chip',\n",
       " u'chock',\n",
       " u'choic',\n",
       " u'choos',\n",
       " u'chop',\n",
       " u'choppi',\n",
       " u'choral',\n",
       " u'chore',\n",
       " u'chose',\n",
       " u'chosen',\n",
       " u'christi',\n",
       " u'christma',\n",
       " u'chronicl',\n",
       " u'chuckl',\n",
       " u'churn',\n",
       " u'cinemat',\n",
       " u'circl',\n",
       " u'circumst',\n",
       " u'citi',\n",
       " u'citizen',\n",
       " u'civil',\n",
       " u'claim',\n",
       " u'clan',\n",
       " u'claptrap',\n",
       " u'clarenc',\n",
       " u'clariti',\n",
       " u'class',\n",
       " u'classconscieni',\n",
       " u'classi',\n",
       " u'classic',\n",
       " u'classifi',\n",
       " u'classism',\n",
       " u'classroom',\n",
       " u'claustrophob',\n",
       " u'clean',\n",
       " u'clear',\n",
       " u'clearer',\n",
       " u'clearli',\n",
       " u'clever',\n",
       " u'clich',\n",
       " u'click',\n",
       " u'cliff',\n",
       " u'cliffhang',\n",
       " u'climact',\n",
       " u'climax',\n",
       " u'climb',\n",
       " u'cling',\n",
       " u'clinic',\n",
       " u'clip',\n",
       " u'close',\n",
       " u'closer',\n",
       " u'closest',\n",
       " u'closet',\n",
       " u'closur',\n",
       " u'cloud',\n",
       " u'cloudi',\n",
       " u'cloy',\n",
       " u'club',\n",
       " u'clubi',\n",
       " u'clue',\n",
       " u'clueless',\n",
       " u'clumsi',\n",
       " u'cluster',\n",
       " u'clutter',\n",
       " u'coars',\n",
       " u'coaster',\n",
       " u'cobbl',\n",
       " u'code',\n",
       " u'cohes',\n",
       " u'cold',\n",
       " u'collaps',\n",
       " u'colleagu',\n",
       " u'collect',\n",
       " u'colleg',\n",
       " u'collegeag',\n",
       " u'collis',\n",
       " u'collus',\n",
       " u'color',\n",
       " u'colorless',\n",
       " u'column',\n",
       " u'combat',\n",
       " u'combin',\n",
       " u'come',\n",
       " u'comedi',\n",
       " u'comeupp',\n",
       " u'comfort',\n",
       " u'comic',\n",
       " u'command',\n",
       " u'comment',\n",
       " u'commentari',\n",
       " u'commiser',\n",
       " u'commit',\n",
       " u'commodifi',\n",
       " u'common',\n",
       " u'commun',\n",
       " u'commut',\n",
       " u'compani',\n",
       " u'companion',\n",
       " u'compar',\n",
       " u'comparison',\n",
       " u'compass',\n",
       " u'compassion',\n",
       " u'compel',\n",
       " u'compendium',\n",
       " u'compens',\n",
       " u'compet',\n",
       " u'competit',\n",
       " u'compil',\n",
       " u'complac',\n",
       " u'complain',\n",
       " u'complaint',\n",
       " u'complet',\n",
       " u'completeley',\n",
       " u'complex',\n",
       " u'complic',\n",
       " u'comprehend',\n",
       " u'compuls',\n",
       " u'comput',\n",
       " u'conceal',\n",
       " u'conceiv',\n",
       " u'concentr',\n",
       " u'concept',\n",
       " u'concern',\n",
       " u'concis',\n",
       " u'conclud',\n",
       " u'conclus',\n",
       " u'concret',\n",
       " u'condemn',\n",
       " u'condit',\n",
       " u'confederaci',\n",
       " u'confess',\n",
       " u'confid',\n",
       " u'confin',\n",
       " u'confirm',\n",
       " u'conflict',\n",
       " u'confront',\n",
       " u'confus',\n",
       " u'confusingli',\n",
       " u'confusiong',\n",
       " u'congratul',\n",
       " u'conjur',\n",
       " u'connect',\n",
       " u'conscienc',\n",
       " u'consciou',\n",
       " u'consensu',\n",
       " u'consequ',\n",
       " u'conserv',\n",
       " u'consid',\n",
       " u'consider',\n",
       " u'consist',\n",
       " u'consolid',\n",
       " u'constant',\n",
       " u'constantli',\n",
       " u'construct',\n",
       " u'consum',\n",
       " u'contain',\n",
       " u'contempl',\n",
       " u'contemporari',\n",
       " u'contemptu',\n",
       " u'content',\n",
       " u'context',\n",
       " u'contin',\n",
       " u'continu',\n",
       " u'contrari',\n",
       " u'contrast',\n",
       " u'contribut',\n",
       " u'contriv',\n",
       " u'control',\n",
       " u'controsept',\n",
       " u'convent',\n",
       " u'converg',\n",
       " u'convers',\n",
       " u'convey',\n",
       " u'convinc',\n",
       " u'convolut',\n",
       " u'cool',\n",
       " u'cope',\n",
       " u'copi',\n",
       " u'copperfield',\n",
       " u'core',\n",
       " u'cormoran',\n",
       " u'corneliu',\n",
       " u'coron',\n",
       " u'correct',\n",
       " u'correctli',\n",
       " u'corrupt',\n",
       " u'cost',\n",
       " u'costco',\n",
       " u'could',\n",
       " u'couldnt',\n",
       " u'council',\n",
       " u'councillor',\n",
       " u'councilman',\n",
       " u'counsellor',\n",
       " u'count',\n",
       " u'counter',\n",
       " u'counterbalanc',\n",
       " u'counterpart',\n",
       " u'counterpoint',\n",
       " u'countless',\n",
       " u'countri',\n",
       " u'countrysid',\n",
       " u'coupl',\n",
       " u'courag',\n",
       " u'cours',\n",
       " u'cover',\n",
       " u'cowardic',\n",
       " u'cozi',\n",
       " u'craft',\n",
       " u'cram',\n",
       " u'crap',\n",
       " u'crappi',\n",
       " u'crappola',\n",
       " u'crash',\n",
       " u'crass',\n",
       " u'crave',\n",
       " u'crazi',\n",
       " u'creat',\n",
       " u'creation',\n",
       " u'creativ',\n",
       " u'creatur',\n",
       " u'credibl',\n",
       " u'creep',\n",
       " u'creepi',\n",
       " u'crescendo',\n",
       " u'cri',\n",
       " u'crime',\n",
       " u'crimin',\n",
       " u'cring',\n",
       " u'crippl',\n",
       " u'criteria',\n",
       " u'critic',\n",
       " u'cross',\n",
       " u'crowd',\n",
       " u'crude',\n",
       " u'cruel',\n",
       " u'cruelest',\n",
       " u'cruelti',\n",
       " u'cruis',\n",
       " u'crumbl',\n",
       " u'crummi',\n",
       " u'cs',\n",
       " u'cubbi',\n",
       " u'cuckoo',\n",
       " u'culmin',\n",
       " u'cultur',\n",
       " u'cumbersom',\n",
       " u'cup',\n",
       " u'cure',\n",
       " u'curios',\n",
       " u'curiou',\n",
       " u'current',\n",
       " u'curs',\n",
       " u'curt',\n",
       " u'curtail',\n",
       " u'curtain',\n",
       " u'cuss',\n",
       " u'cussi',\n",
       " u'cut',\n",
       " u'cutout',\n",
       " u'cword',\n",
       " u'cycl',\n",
       " u'cynic',\n",
       " u'dahl',\n",
       " u'daili',\n",
       " u'dalla',\n",
       " u'damag',\n",
       " u'dan',\n",
       " u'dandi',\n",
       " u'danger',\n",
       " u'dangl',\n",
       " u'daniel',\n",
       " u'dare',\n",
       " u'dark',\n",
       " u'darker',\n",
       " u'darkest',\n",
       " u'darkli',\n",
       " u'darn',\n",
       " u'dash',\n",
       " u'dataentri',\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4621"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "train_X = vectorizer.transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1746x4621 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 44401 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1746, 4621)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OVERFIT because too many degrees of freedom!!!! Too many variables to small number of samples!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.todense() # to show a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Train uncalibrated random forest classifier on whole train and validation\n",
    "# data and evaluate on test data\n",
    "clf = RandomForestClassifier(n_estimators=400,)\n",
    "clf.fit(train_X, train_c)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My training score is 0.997136311569\n",
      "My generalization score is 0.550687285223\n"
     ]
    }
   ],
   "source": [
    "print \"My training score is\", clf.score(train_X, train_c)\n",
    "print \"My generalization score is\", clf.score(test_X, test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58989869472043643"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(clf, train_X, train_c, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2').fit(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My training score is 0.862542955326\n",
      "My generalization score is 0.591065292096\n"
     ]
    }
   ],
   "source": [
    "print \"My training score is\", model.score(train_X, train_c)\n",
    "print \"My generalization score is\", model.score(test_X, test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True Class</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypothesized Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>255</td>\n",
       "      <td>98</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>163</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>127</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True Class           -1    0    1\n",
       "Hypothesized Class               \n",
       "-1                  255   98   36\n",
       " 0                   72  163   82\n",
       " 1                   61  127  270"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_hat = model.predict(test_X)\n",
    "\n",
    "pd.crosstab(c_hat,\n",
    "    test_c,\n",
    "    rownames = ['Hypothesized Class'],\n",
    "    colnames = ['True Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60890317553087869"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(model, train_X, train_c, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
